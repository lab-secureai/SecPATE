{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYwjHaEAmnGP",
        "outputId": "6a83c220-b21a-4438-ee10-4c440974876f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3900, 3) (1672, 3)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 0.7392 - loss: 0.5737\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.8733 - loss: 0.3262\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.9097 - loss: 0.1720\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 197ms/step - accuracy: 0.9779 - loss: 0.0792\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.9916 - loss: 0.0488\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.9944 - loss: 0.0242\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.9948 - loss: 0.0263\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.9958 - loss: 0.0180\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - accuracy: 0.9995 - loss: 0.0030\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0027\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 150ms/step - accuracy: 0.8420 - loss: 0.5351\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.8743 - loss: 0.2313\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 229ms/step - accuracy: 0.9871 - loss: 0.0599\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.9815 - loss: 0.1019\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.9880 - loss: 0.0373\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.9957 - loss: 0.0258\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.9949 - loss: 0.0226\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 223ms/step - accuracy: 0.9991 - loss: 0.0076\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 3.9219e-04\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.7130 - loss: 0.5574\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step - accuracy: 0.8817 - loss: 0.2553\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.9702 - loss: 0.1727\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9862 - loss: 0.0784\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.9899 - loss: 0.0306\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.9978 - loss: 0.0136\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - accuracy: 0.9966 - loss: 0.0081\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 2.9239e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.5331e-04\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - accuracy: 0.8442 - loss: 0.5496\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 197ms/step - accuracy: 0.9071 - loss: 0.2541\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - accuracy: 0.9530 - loss: 0.1465\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.9938 - loss: 0.0784\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.9895 - loss: 0.0486\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9900 - loss: 0.0622\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 206ms/step - accuracy: 0.9942 - loss: 0.0364\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 143ms/step - accuracy: 0.9905 - loss: 0.0427\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.9967 - loss: 0.0200\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.9992 - loss: 0.0058\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.8660 - loss: 0.5453\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.8637 - loss: 0.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9634 - loss: 0.1164\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.9726 - loss: 0.1009\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - accuracy: 0.9841 - loss: 0.0560\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - accuracy: 0.9888 - loss: 0.0466\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.9936 - loss: 0.0321\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - accuracy: 0.9912 - loss: 0.0449\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 145ms/step - accuracy: 0.9966 - loss: 0.0161\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - accuracy: 0.9964 - loss: 0.0239\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "[array([[3.9218462e-04],\n",
            "       [1.7789837e-04],\n",
            "       [8.1186765e-01],\n",
            "       ...,\n",
            "       [1.8556052e-04],\n",
            "       [1.7745554e-04],\n",
            "       [8.6939393e-04]], dtype=float32), array([[9.9979663e-01],\n",
            "       [1.4114115e-04],\n",
            "       [1.7903101e-04],\n",
            "       ...,\n",
            "       [1.3945394e-04],\n",
            "       [1.3556059e-04],\n",
            "       [1.9771706e-04]], dtype=float32), array([[1.2660335e-04],\n",
            "       [4.5719924e-05],\n",
            "       [5.2504992e-04],\n",
            "       ...,\n",
            "       [5.3739452e-05],\n",
            "       [4.4675362e-05],\n",
            "       [1.8644394e-04]], dtype=float32), array([[2.2043709e-03],\n",
            "       [3.5173149e-04],\n",
            "       [9.8258245e-01],\n",
            "       ...,\n",
            "       [3.2596302e-04],\n",
            "       [3.0118180e-04],\n",
            "       [1.5176791e-03]], dtype=float32), array([[0.00079355],\n",
            "       [0.00066705],\n",
            "       [0.00190542],\n",
            "       ...,\n",
            "       [0.00079405],\n",
            "       [0.00069202],\n",
            "       [0.00100591]], dtype=float32)]\n",
            "HARD VOTE\n",
            "Student Train\n",
            "Epoch 1/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.7829 - loss: 0.4822\n",
            "Epoch 2/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - accuracy: 0.9199 - loss: 0.1603\n",
            "Epoch 3/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.9879 - loss: 0.0489\n",
            "Epoch 4/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - accuracy: 0.9862 - loss: 0.0511\n",
            "Epoch 5/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.9971 - loss: 0.0114\n",
            "Epoch 6/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step - accuracy: 0.9998 - loss: 0.0010    \n",
            "Epoch 7/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 175ms/step - accuracy: 0.9976 - loss: 0.0106\n",
            "Epoch 8/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.9983 - loss: 0.0060\n",
            "Epoch 9/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.9993 - loss: 0.0029\n",
            "Epoch 10/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 8.4894e-04\n",
            "Student Test\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9339 - loss: 0.4533\n",
            "Final test accuracy on remaining 1/3: 95.34%\n"
          ]
        }
      ],
      "source": [
        "#PATE VOTE SMS SPAM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "\n",
        "# Đọc dữ liệu\n",
        "df = pd.read_csv('/content/sample_data/spam.csv')\n",
        "\n",
        "# Mã hóa nhãn: spam=1, ham=0\n",
        "df['target'] = df['label'].map({'spam': 1, 'ham': 0})\n",
        "\n",
        "# b) Tách dữ liệu huấn luyện và kiểm tra (70% train, 30% test)\n",
        "df_train = df.sample(frac=0.7, random_state=11)\n",
        "df_test = df.drop(df_train.index)\n",
        "print(df_train.shape, df_test.shape)\n",
        "\n",
        "y_train = df_train['target'].values\n",
        "y_test = df_test['target'].values\n",
        "X_train = df_train['sms'].values\n",
        "X_test = df_test['sms'].values\n",
        "\n",
        "# Tạo Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_dict = tokenizer.index_word\n",
        "\n",
        "# Xử lý văn bản: chuyển văn bản thành các chỉ số\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding các chuỗi văn bản để có chiều dài cố định\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=20, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=20, padding='post')\n",
        "\n",
        "# Tham số cho mô hình\n",
        "laenge_pads = 20\n",
        "anz_woerter = len(word_dict)  # Lấy số lượng từ trong từ điển\n",
        "\n",
        "# Định nghĩa mô hình LSTM\n",
        "def create_lstm_model():\n",
        "    lstm_model = Sequential()\n",
        "    lstm_model.add(Embedding(input_dim=anz_woerter + 1, output_dim=20, input_length=laenge_pads))\n",
        "    lstm_model.add(LSTM(400))\n",
        "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "    lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return lstm_model\n",
        "\n",
        "# b) Chia dữ liệu huấn luyện thành n client\n",
        "n_clients = 5  # Số lượng client\n",
        "train_data_splits_X = np.array_split(X_train_pad, n_clients)\n",
        "train_data_splits_y = np.array_split(y_train, n_clients)\n",
        "\n",
        "# Huấn luyện mô hình cho mỗi client\n",
        "client_models = []\n",
        "for i in range(n_clients):\n",
        "    X_client = train_data_splits_X[i]\n",
        "    y_client = train_data_splits_y[i]\n",
        "\n",
        "    client_model = create_lstm_model()\n",
        "    client_model.fit(X_client, y_client, epochs=10, batch_size=64)\n",
        "    client_models.append(client_model)\n",
        "\n",
        "# c) Dùng 2/3 dữ liệu kiểm tra để gửi tới các mô hình client và dự đoán\n",
        "split_index = len(X_test_pad) // 3  # Tính chỉ số cắt để chia dữ liệu test thành 2/3 và 1/3\n",
        "X_test_2_3 = X_test_pad[:2 * split_index]\n",
        "y_test_2_3 = y_test[:2 * split_index]\n",
        "X_test_1_3 = X_test_pad[2 * split_index:]\n",
        "y_test_1_3 = y_test[2 * split_index:]\n",
        "\n",
        "client_predictions = []\n",
        "for model in client_models:\n",
        "    predictions = model.predict(X_test_2_3)\n",
        "    client_predictions.append(predictions)\n",
        "\n",
        "\n",
        "print(client_predictions)\n",
        "# d) Sử dụng hard vote để xác định nhãn cuối cùng\n",
        "def hard_vote(predictions):\n",
        "    print(\"HARD VOTE\")\n",
        "    predictions = np.array(predictions)\n",
        "    vote = np.round(np.mean(predictions, axis=0))\n",
        "    return vote\n",
        "\n",
        "final_predictions = hard_vote(client_predictions)\n",
        "\n",
        "# e) Sử dụng bộ dữ liệu đã gán nhãn để huấn luyện lại mô hình (chỉ dùng X_test_2_3 để huấn luyện)\n",
        "print(\"Student Train\")\n",
        "final_model = create_lstm_model()\n",
        "final_model.fit(X_test_2_3, final_predictions.flatten(), epochs=10, batch_size=64)\n",
        "\n",
        "# f) Đánh giá độ chính xác trên 1/3 dữ liệu kiểm tra còn lại\n",
        "print(\"Student Test\")\n",
        "loss, accuracy = final_model.evaluate(X_test_1_3, y_test_1_3, verbose=1)\n",
        "print(f\"Final test accuracy on remaining 1/3: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7dOMNV-shBe",
        "outputId": "80eac8ca-cbfa-4f89-ecaa-16633e518cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 1. LOAD DATA ===\n",
            "Đang thử đọc file với encoding='utf-8' ...\n",
            "Đọc thành công với encoding='utf-8'\n",
            "5 dòng đầu của dữ liệu:\n",
            "  label                                                sms\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "Đã chọn cột label = 'label', cột text = 'sms'\n",
            "=== 2. CHUẨN HOÁ NHÃN ===\n",
            "Phân bố nhãn:\n",
            "target\n",
            "0    4825\n",
            "1     747\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== 3. CHIA TRAIN / TEST ===\n",
            "Kích thước train: (3900, 3)\n",
            "Kích thước test : (1672, 3)\n",
            "\n",
            "=== 4. TOKENIZE & PADDING ===\n",
            "Số lượng từ trong vocab: 7376\n",
            "Shape X_train_pad: (3900, 20)\n",
            "Shape X_test_pad : (1672, 20)\n",
            "\n",
            "=== 5. CHIA DỮ LIỆU CHO CÁC TEACHER (CLIENT) ===\n",
            "  Client 1: X=(780, 20), y=(780,)\n",
            "  Client 2: X=(780, 20), y=(780,)\n",
            "  Client 3: X=(780, 20), y=(780,)\n",
            "  Client 4: X=(780, 20), y=(780,)\n",
            "  Client 5: X=(780, 20), y=(780,)\n",
            "\n",
            "=== 6. TRAIN CÁC TEACHER MODEL ===\n",
            "\n",
            "--- Training client 1/5 ---\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8688 - loss: 0.6013\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8897 - loss: 0.2251\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9211 - loss: 0.1421\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9847 - loss: 0.0988\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9916 - loss: 0.0343\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9933 - loss: 0.0267\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9981 - loss: 0.0098\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9992 - loss: 0.0062\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9964 - loss: 0.0043\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.8825e-04\n",
            "\n",
            "--- Training client 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.7379 - loss: 0.6141\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8729 - loss: 0.2852\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9020 - loss: 0.2227\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9443 - loss: 0.1710\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9860 - loss: 0.0733\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9946 - loss: 0.0256\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9984 - loss: 0.0124\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0026\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.0189e-04\n",
            "\n",
            "--- Training client 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8785 - loss: 0.6049\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8879 - loss: 0.2749\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8920 - loss: 0.2389\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9115 - loss: 0.1803\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9742 - loss: 0.1112\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9847 - loss: 0.0631\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9961 - loss: 0.0212\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0095\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0064\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9989 - loss: 0.0075\n",
            "\n",
            "--- Training client 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8162 - loss: 0.6014\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8670 - loss: 0.2626\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9310 - loss: 0.2047\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9826 - loss: 0.0732\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9867 - loss: 0.0478\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9961 - loss: 0.0209\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9975 - loss: 0.0200\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9964 - loss: 0.0240\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9996 - loss: 0.0039\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9964 - loss: 0.0256\n",
            "\n",
            "--- Training client 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.8591 - loss: 0.5976\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8498 - loss: 0.3142\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8655 - loss: 0.2321\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9541 - loss: 0.1253\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9789 - loss: 0.0541\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9893 - loss: 0.0487\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9919 - loss: 0.0445\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9942 - loss: 0.0296\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9986 - loss: 0.0118\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9980 - loss: 0.0137\n",
            "\n",
            "=== 7. CHIA TẬP TEST: 2/3 DÙNG ĐỂ VOTE, 1/3 DÙNG ĐỂ TEST STUDENT ===\n",
            "X_test_2_3: (1114, 20) y_test_2_3: (1114,)\n",
            "X_test_1_3: (558, 20) y_test_1_3: (558,)\n",
            "\n",
            "=== 8. TEACHER PREDICTIONS TRÊN 2/3 TẬP TEST ===\n",
            "  Dự đoán từ client 1 ...\n",
            "  Dự đoán từ client 2 ...\n",
            "  Dự đoán từ client 3 ...\n",
            "  Dự đoán từ client 4 ...\n",
            "  Dự đoán từ client 5 ...\n",
            "Số mảng dự đoán nhận được: 5\n",
            "Shape dự đoán từ client 1: (1114, 1)\n",
            "\n",
            "=== 6. HARD VOTE - SECURE AGGREGATION (PATE style) ===\n",
            "Số client    : 5\n",
            "Số mẫu vote  : 1114\n",
            "GAMMA        : 2 -> scale = 100\n",
            "max_sum (giới hạn tìm log): 500\n",
            "Phase 1: Khởi tạo khoá cho từng teacher\n",
            "Giá trị X (tổng hợp): 8471743\n",
            "Giá trị Y (tổng hợp): 7522174\n",
            "Phase 2 - Step 1: Lượng tử hoá dự đoán của từng teacher\n",
            "Phase 2 - Step 2: Mã hoá dự đoán của từng teacher\n",
            "Phase 2 - Step 3: Aggregator nhân các bản mã V_i lại với nhau\n",
            "Phase 2 - Step 4: Giải discrete log để khôi phục tổng lượng tử S^(j)\n",
            "  Mẫu 0 - V_agg=5322942, S=100\n",
            "  Mẫu 1 - V_agg=1, S=0\n",
            "  Mẫu 2 - V_agg=5402839, S=201\n",
            "Phase 2 - Step 5: Chia ngược scale để lấy tổng xác suất\n",
            "Một vài mẫu demo (sample 0-2):\n",
            "  Sample 0:\n",
            "    Dự đoán từng teacher: [7.7987189e-04 9.9728781e-01 9.9284248e-04 2.0507711e-03 3.2588397e-03]\n",
            "    Tổng lượng tử S      : 100\n",
            "    Tổng xác suất ~      : 1.0\n",
            "    Xác suất TB          : 0.2\n",
            "    Nhãn cuối cùng       : 0\n",
            "  Sample 1:\n",
            "    Dự đoán từng teacher: [0.00025137 0.00040326 0.00079482 0.00117302 0.00191337]\n",
            "    Tổng lượng tử S      : 0\n",
            "    Tổng xác suất ~      : 0.0\n",
            "    Xác suất TB          : 0.0\n",
            "    Nhãn cuối cùng       : 0\n",
            "  Sample 2:\n",
            "    Dự đoán từng teacher: [9.9247408e-01 6.7031774e-04 5.0378004e-03 9.9912453e-01 7.2678961e-03]\n",
            "    Tổng lượng tử S      : 201\n",
            "    Tổng xác suất ~      : 2.01\n",
            "    Xác suất TB          : 0.40199999999999997\n",
            "    Nhãn cuối cùng       : 0\n",
            "\n",
            "=== 9. STUDENT TRAIN ===\n",
            "Epoch 1/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8643 - loss: 0.5569\n",
            "Epoch 2/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8821 - loss: 0.2201\n",
            "Epoch 3/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9665 - loss: 0.1210\n",
            "Epoch 4/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9900 - loss: 0.0396\n",
            "Epoch 5/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9981 - loss: 0.0155\n",
            "Epoch 6/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9987 - loss: 0.0091\n",
            "Epoch 7/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9969 - loss: 0.0101\n",
            "Epoch 8/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9971 - loss: 0.0069\n",
            "Epoch 9/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 5.7029e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 3.8374e-04\n",
            "\n",
            "=== 10. STUDENT TEST ===\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9394 - loss: 0.4085\n",
            "\n",
            "Final test accuracy on remaining 1/3: 95.34%\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# PATE VOTE SMS SPAM - SECURE AGGREGATION\n",
        "# ============================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "\n",
        "# =======================\n",
        "# 0. HÀM HỖ TRỢ\n",
        "# =======================\n",
        "\n",
        "def load_sms_data(path):\n",
        "    print(\"=== 1. LOAD DATA ===\")\n",
        "    # Thử một vài encoding phổ biến\n",
        "    for enc in [\"utf-8\", \"latin-1\", \"ISO-8859-1\"]:\n",
        "        try:\n",
        "            print(f\"Đang thử đọc file với encoding='{enc}' ...\")\n",
        "            df_ = pd.read_csv(path, encoding=enc)\n",
        "            print(f\"Đọc thành công với encoding='{enc}'\")\n",
        "            break\n",
        "        except UnicodeDecodeError as e:\n",
        "            print(f\"  -> Lỗi với encoding='{enc}': {e}\")\n",
        "            df_ = None\n",
        "\n",
        "    if df_ is None:\n",
        "        raise ValueError(\"Không đọc được file CSV với các encoding thử nghiệm.\")\n",
        "\n",
        "    print(\"5 dòng đầu của dữ liệu:\")\n",
        "    print(df_.head())\n",
        "\n",
        "    # Chuẩn hóa tên cột: label và sms/message\n",
        "    label_col_candidates = [\"label\", \"Label\", \"v1\", \"category\", \"Category\"]\n",
        "    text_col_candidates  = [\"sms\", \"SMS\", \"message\", \"Message\", \"v2\", \"text\", \"Text\"]\n",
        "\n",
        "    label_col = None\n",
        "    text_col  = None\n",
        "\n",
        "    for c in label_col_candidates:\n",
        "        if c in df_.columns:\n",
        "            label_col = c\n",
        "            break\n",
        "\n",
        "    for c in text_col_candidates:\n",
        "        if c in df_.columns:\n",
        "            text_col = c\n",
        "            break\n",
        "\n",
        "    if label_col is None or text_col is None:\n",
        "        raise ValueError(f\"Không tìm thấy cột label/text trong file. Columns: {df_.columns}\")\n",
        "\n",
        "    print(f\"Đã chọn cột label = '{label_col}', cột text = '{text_col}'\")\n",
        "\n",
        "    df = df_[[label_col, text_col]].copy()\n",
        "    df.columns = [\"label\", \"sms\"]  # chuẩn tên cột\n",
        "\n",
        "    # Chuẩn hóa nhãn: spam=1, ham=0\n",
        "    print(\"=== 2. CHUẨN HOÁ NHÃN ===\")\n",
        "    if set(df[\"label\"].unique()) <= {\"spam\", \"ham\"}:\n",
        "        df[\"target\"] = df[\"label\"].map({\"spam\": 1, \"ham\": 0})\n",
        "    else:\n",
        "        df[\"label_str\"] = df[\"label\"].astype(str).str.lower()\n",
        "        df[\"target\"] = df[\"label_str\"].map(\n",
        "            {\"spam\": 1, \"ham\": 0, \"1\": 1, \"0\": 0}\n",
        "        )\n",
        "        if df[\"target\"].isna().any():\n",
        "            raise ValueError(\"Không map được toàn bộ nhãn spam/ham -> 1/0, kiểm tra dữ liệu!\")\n",
        "\n",
        "    print(\"Phân bố nhãn:\")\n",
        "    print(df[\"target\"].value_counts())\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 1. MÔ HÌNH LSTM\n",
        "# =======================\n",
        "\n",
        "def create_lstm_model(vocab_size, max_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size + 1, output_dim=20, input_length=max_len))\n",
        "    model.add(LSTM(128))  # nhẹ hơn 400 một chút cho demo\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 2. THAM SỐ PATE\n",
        "# =======================\n",
        "\n",
        "\n",
        "P = 10000019\n",
        "G = 2\n",
        "GAMMA = 2\n",
        "\n",
        "def discrete_log_bruteforce(g, h, p, max_log):\n",
        "    \"\"\"\n",
        "    Tìm S sao cho g^S ≡ h (mod p), với 0 <= S <= max_log.\n",
        "    Brute-force: chỉ nên dùng demo / max_log nhỏ.\n",
        "    \"\"\"\n",
        "    cur = 1\n",
        "    for s in range(max_log + 1):\n",
        "        if cur == h:\n",
        "            return s\n",
        "        cur = (cur * g) % p\n",
        "    raise ValueError(\"Không tìm được discrete log trong khoảng cho phép\")\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 3. HARD VOTE SECURE AGGREGATION\n",
        "# =======================\n",
        "\n",
        "def hard_vote_secure_agg(predictions, p=P, g=G, gamma=GAMMA):\n",
        "    \"\"\"\n",
        "    predictions: list length = n_clients,\n",
        "                 mỗi phần tử là mảng (n_samples, 1) hoặc (n_samples,)\n",
        "                 -> xác suất spam (output sigmoid) của từng teacher.\n",
        "\n",
        "    Trả về:\n",
        "        labels: mảng (n_samples, 1) nhãn 0/1.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== 6. HARD VOTE - SECURE AGGREGATION (PATE style) ===\")\n",
        "\n",
        "    # preds: (n_clients, n_samples)\n",
        "    preds_list = [np.array(pr).reshape(-1) for pr in predictions]\n",
        "    preds = np.stack(preds_list, axis=0)  # (n_clients, n_samples)\n",
        "\n",
        "    n_clients, n_samples = preds.shape\n",
        "    scale = 10 ** gamma\n",
        "    max_sum = n_clients * scale  # O_i ∈ [0,1] -> \\tilde{O}_i ∈ [0, scale]\n",
        "\n",
        "    print(f\"Số client    : {n_clients}\")\n",
        "    print(f\"Số mẫu vote  : {n_samples}\")\n",
        "    print(f\"GAMMA        : {gamma} -> scale = {scale}\")\n",
        "    print(f\"max_sum (giới hạn tìm log): {max_sum}\")\n",
        "\n",
        "    # ---- Phase 1: Initialization ----\n",
        "    print(\"Phase 1: Khởi tạo khoá cho từng teacher\")\n",
        "\n",
        "    # Mỗi teacher có khóa riêng x_i, y_i\n",
        "    x = np.random.randint(1, p - 1, size=n_clients, dtype=np.int64)\n",
        "    y = np.random.randint(1, p - 1, size=n_clients, dtype=np.int64)\n",
        "\n",
        "    X_i = [pow(g, int(x_i), p) for x_i in x]\n",
        "    Y_i = [pow(g, int(y_i), p) for y_i in y]\n",
        "\n",
        "    X = 1\n",
        "    Y = 1\n",
        "    for Xi in X_i:\n",
        "        X = (X * Xi) % p\n",
        "    for Yi in Y_i:\n",
        "        Y = (Y * Yi) % p\n",
        "\n",
        "    print(f\"Giá trị X (tổng hợp): {X}\")\n",
        "    print(f\"Giá trị Y (tổng hợp): {Y}\")\n",
        "\n",
        "    # ---- Phase 2: Secure computation ----\n",
        "\n",
        "    # Bước 1: lượng tử hoá dự đoán\n",
        "    print(\"Phase 2 - Step 1: Lượng tử hoá dự đoán của từng teacher\")\n",
        "    quantized = (preds * scale).round().astype(int)  # (n_clients, n_samples)\n",
        "\n",
        "    # Bước 2: mỗi teacher mã hoá dự đoán của mình\n",
        "    print(\"Phase 2 - Step 2: Mã hoá dự đoán của từng teacher\")\n",
        "    V_all = []\n",
        "    for i in range(n_clients):\n",
        "        # X^{y_i} / Y^{x_i} (mod p)\n",
        "        X_y = pow(X, int(y[i]), p)\n",
        "        Y_x = pow(Y, int(x[i]), p)\n",
        "        Y_x_inv = pow(Y_x, p - 2, p)  # nghịch đảo modulo p (Fermat)\n",
        "        key_factor = (X_y * Y_x_inv) % p\n",
        "\n",
        "        V_i = []\n",
        "        for s in range(n_samples):\n",
        "            g_pow = pow(g, int(quantized[i, s]), p)\n",
        "            V_is = (key_factor * g_pow) % p\n",
        "            V_i.append(V_is)\n",
        "        V_all.append(np.array(V_i, dtype=np.int64))\n",
        "\n",
        "    V_all = np.stack(V_all, axis=0)  # (n_clients, n_samples)\n",
        "\n",
        "    # Bước 3: Aggregator nhân các vector V_i\n",
        "    print(\"Phase 2 - Step 3: Aggregator nhân các bản mã V_i lại với nhau\")\n",
        "    V_agg = np.ones(n_samples, dtype=np.int64)\n",
        "    for i in range(n_clients):\n",
        "        V_agg = (V_agg * V_all[i]) % p\n",
        "\n",
        "    # Bước 4: Giải discrete log để tìm tổng lượng tử S^(j)\n",
        "    print(\"Phase 2 - Step 4: Giải discrete log để khôi phục tổng lượng tử S^(j)\")\n",
        "    S = np.zeros(n_samples, dtype=np.int64)\n",
        "    for s in range(n_samples):\n",
        "        S[s] = discrete_log_bruteforce(g, int(V_agg[s]), p, max_sum)\n",
        "        if s < 3:  # in demo một vài mẫu đầu\n",
        "            print(f\"  Mẫu {s} - V_agg={V_agg[s]}, S={S[s]}\")\n",
        "\n",
        "    # Bước 5: Khôi phục tổng thực O_sum^(j) = S^(j) / 10^gamma\n",
        "    print(\"Phase 2 - Step 5: Chia ngược scale để lấy tổng xác suất\")\n",
        "    O_sum = S.astype(float) / scale  # ∑_i O_i^(j)\n",
        "\n",
        "    # Trung bình xác suất và hard vote\n",
        "    avg_prob = O_sum / n_clients\n",
        "    labels = (avg_prob >= 0.5).astype(int).reshape(-1, 1)\n",
        "\n",
        "    print(\"Một vài mẫu demo (sample 0-2):\")\n",
        "    for idx in range(min(3, n_samples)):\n",
        "        print(f\"  Sample {idx}:\")\n",
        "        print(f\"    Dự đoán từng teacher: {preds[:, idx]}\")\n",
        "        print(f\"    Tổng lượng tử S      : {S[idx]}\")\n",
        "        print(f\"    Tổng xác suất ~      : {O_sum[idx]}\")\n",
        "        print(f\"    Xác suất TB          : {avg_prob[idx]}\")\n",
        "        print(f\"    Nhãn cuối cùng       : {labels[idx, 0]}\")\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 4. MAIN FLOW\n",
        "# =======================\n",
        "\n",
        "# Đường dẫn file CSV của bạn\n",
        "CSV_PATH = \"/content/sample_data/spam.csv\"   # đổi lại nếu cần (spam_1.csv, ...)\n",
        "\n",
        "# 4.1 Load và chuẩn dữ liệu\n",
        "df = load_sms_data(CSV_PATH)\n",
        "\n",
        "# 4.2 Tách train/test (70% / 30%)\n",
        "print(\"\\n=== 3. CHIA TRAIN / TEST ===\")\n",
        "df_train = df.sample(frac=0.7, random_state=11)\n",
        "df_test = df.drop(df_train.index)\n",
        "print(\"Kích thước train:\", df_train.shape)\n",
        "print(\"Kích thước test :\", df_test.shape)\n",
        "\n",
        "y_train = df_train[\"target\"].values\n",
        "y_test = df_test[\"target\"].values\n",
        "X_train = df_train[\"sms\"].values\n",
        "X_test = df_test[\"sms\"].values\n",
        "\n",
        "# 4.3 Tokenizer & padding\n",
        "print(\"\\n=== 4. TOKENIZE & PADDING ===\")\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_dict = tokenizer.index_word\n",
        "vocab_size = len(word_dict)\n",
        "print(\"Số lượng từ trong vocab:\", vocab_size)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "MAX_LEN = 20\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "print(\"Shape X_train_pad:\", X_train_pad.shape)\n",
        "print(\"Shape X_test_pad :\", X_test_pad.shape)\n",
        "\n",
        "# 4.4 Chia dữ liệu train thành n client\n",
        "print(\"\\n=== 5. CHIA DỮ LIỆU CHO CÁC TEACHER (CLIENT) ===\")\n",
        "n_clients = 5\n",
        "train_data_splits_X = np.array_split(X_train_pad, n_clients)\n",
        "train_data_splits_y = np.array_split(y_train, n_clients)\n",
        "\n",
        "for i in range(n_clients):\n",
        "    print(f\"  Client {i+1}: X={train_data_splits_X[i].shape}, y={train_data_splits_y[i].shape}\")\n",
        "\n",
        "# 4.5 Huấn luyện mô hình cho mỗi client (teacher)\n",
        "print(\"\\n=== 6. TRAIN CÁC TEACHER MODEL ===\")\n",
        "client_models = []\n",
        "for i in range(n_clients):\n",
        "    print(f\"\\n--- Training client {i+1}/{n_clients} ---\")\n",
        "    X_client = train_data_splits_X[i]\n",
        "    y_client = train_data_splits_y[i]\n",
        "\n",
        "    model = create_lstm_model(vocab_size=vocab_size, max_len=MAX_LEN)\n",
        "    model.fit(X_client, y_client, epochs=10, batch_size=64, verbose=1)  # epochs nhỏ cho nhanh\n",
        "    client_models.append(model)\n",
        "\n",
        "# 4.6 Chia tập test: 2/3 cho teacher vote, 1/3 cho student test\n",
        "print(\"\\n=== 7. CHIA TẬP TEST: 2/3 DÙNG ĐỂ VOTE, 1/3 DÙNG ĐỂ TEST STUDENT ===\")\n",
        "split_index = len(X_test_pad) // 3\n",
        "X_test_2_3 = X_test_pad[:2 * split_index]\n",
        "y_test_2_3 = y_test[:2 * split_index]\n",
        "X_test_1_3 = X_test_pad[2 * split_index:]\n",
        "y_test_1_3 = y_test[2 * split_index:]\n",
        "\n",
        "print(\"X_test_2_3:\", X_test_2_3.shape, \"y_test_2_3:\", y_test_2_3.shape)\n",
        "print(\"X_test_1_3:\", X_test_1_3.shape, \"y_test_1_3:\", y_test_1_3.shape)\n",
        "\n",
        "# 4.7 Cho các teacher dự đoán trên 2/3 test\n",
        "print(\"\\n=== 8. TEACHER PREDICTIONS TRÊN 2/3 TẬP TEST ===\")\n",
        "client_predictions = []\n",
        "for i, model in enumerate(client_models):\n",
        "    print(f\"  Dự đoán từ client {i+1} ...\")\n",
        "    preds = model.predict(X_test_2_3, verbose=0)\n",
        "    client_predictions.append(preds)\n",
        "\n",
        "print(\"Số mảng dự đoán nhận được:\", len(client_predictions))\n",
        "print(\"Shape dự đoán từ client 1:\", client_predictions[0].shape)\n",
        "\n",
        "# 4.8 Hard vote theo giao thức secure aggregation\n",
        "final_predictions = hard_vote_secure_agg(client_predictions)\n",
        "\n",
        "# 4.9 Huấn luyện student model với dữ liệu đã gán nhãn\n",
        "print(\"\\n=== 9. STUDENT TRAIN ===\")\n",
        "student_model = create_lstm_model(vocab_size=vocab_size, max_len=MAX_LEN)\n",
        "student_model.fit(X_test_2_3, final_predictions.flatten(), epochs=10, batch_size=64, verbose=1)\n",
        "\n",
        "# 4.10 Đánh giá student model trên 1/3 test còn lại\n",
        "print(\"\\n=== 10. STUDENT TEST ===\")\n",
        "loss, accuracy = student_model.evaluate(X_test_1_3, y_test_1_3, verbose=1)\n",
        "print(f\"\\nFinal test accuracy on remaining 1/3: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8BIeP1rxMVP",
        "outputId": "cd4ec596-413e-44b7-d689-78cdc8e0dd18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 1. ĐỌC DỮ LIỆU MNIST ===\n",
            "  X_train shape: (60000, 28, 28)\n",
            "  X_test  shape: (10000, 28, 28)\n",
            "\n",
            "=== 2. TIỀN XỬ LÝ DỮ LIỆU ===\n",
            "  Sau reshape:\n",
            "  X_train shape: (60000, 28, 28, 1)\n",
            "  X_test  shape: (10000, 28, 28, 1)\n",
            "\n",
            "=== 3. CHIA TẬP TEST: 2/3 DÙNG PATE, 1/3 DÙNG TEST STUDENT ===\n",
            "  X_test_2_3: (6666, 28, 28, 1) y_test_2_3: (6666,)\n",
            "  X_test_1_3: (3334, 28, 28, 1) y_test_1_3: (3334,)\n",
            "\n",
            "=== 4. CHIA DỮ LIỆU HUẤN LUYỆN CHO CÁC TEACHER ===\n",
            "  Client 1: X=(12000, 28, 28, 1), y=(12000,)\n",
            "  Client 2: X=(12000, 28, 28, 1), y=(12000,)\n",
            "  Client 3: X=(12000, 28, 28, 1), y=(12000,)\n",
            "  Client 4: X=(12000, 28, 28, 1), y=(12000,)\n",
            "  Client 5: X=(12000, 28, 28, 1), y=(12000,)\n",
            "\n",
            "=== 5. HUẤN LUYỆN MỖI TEACHER (CLIENT) ===\n",
            "\n",
            "--- Training client 1/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7385 - loss: 0.8826\n",
            "Epoch 2/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1461\n",
            "Epoch 3/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1005\n",
            "Epoch 4/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0727\n",
            "Epoch 5/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0528\n",
            "Epoch 6/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0361\n",
            "Epoch 7/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0279\n",
            "Epoch 8/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0229\n",
            "Epoch 9/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0212\n",
            "Epoch 10/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0170\n",
            "\n",
            "--- Training client 2/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7711 - loss: 0.8476\n",
            "Epoch 2/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9567 - loss: 0.1305\n",
            "Epoch 3/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0817\n",
            "Epoch 4/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0547\n",
            "Epoch 5/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0349\n",
            "Epoch 6/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0258\n",
            "Epoch 7/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0226\n",
            "Epoch 8/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0178\n",
            "Epoch 9/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0146\n",
            "Epoch 10/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0140\n",
            "\n",
            "--- Training client 3/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7356 - loss: 0.8781\n",
            "Epoch 2/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1186\n",
            "Epoch 3/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.0782\n",
            "Epoch 4/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0581\n",
            "Epoch 5/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0418\n",
            "Epoch 6/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0295\n",
            "Epoch 7/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0210\n",
            "Epoch 8/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0150\n",
            "Epoch 9/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0114\n",
            "Epoch 10/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0170\n",
            "\n",
            "--- Training client 4/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7120 - loss: 0.9043\n",
            "Epoch 2/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.1330\n",
            "Epoch 3/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.0829\n",
            "Epoch 4/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0592\n",
            "Epoch 5/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0446\n",
            "Epoch 6/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0313\n",
            "Epoch 7/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0226\n",
            "Epoch 8/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0174\n",
            "Epoch 9/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0200\n",
            "Epoch 10/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0116\n",
            "\n",
            "--- Training client 5/5 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7514 - loss: 0.8366\n",
            "Epoch 2/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.1136\n",
            "Epoch 3/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0720\n",
            "Epoch 4/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0534\n",
            "Epoch 5/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0386\n",
            "Epoch 6/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0280\n",
            "Epoch 7/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0204\n",
            "Epoch 8/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0192\n",
            "Epoch 9/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0158\n",
            "Epoch 10/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0133\n",
            "\n",
            "=== 6. TEACHER PREDICTIONS TRÊN 2/3 TẬP TEST ===\n",
            "  Dự đoán từ client 1 ...\n",
            "  Dự đoán từ client 2 ...\n",
            "  Dự đoán từ client 3 ...\n",
            "  Dự đoán từ client 4 ...\n",
            "  Dự đoán từ client 5 ...\n",
            "  Số mảng dự đoán nhận được: 5\n",
            "  Shape dự đoán từ client 1: (6666, 10)\n",
            "\n",
            "=== 7. HARD VOTE - SECURE AGGREGATION (PATE, MULTI-CLASS) ===\n",
            "  Số client       : 5\n",
            "  Số mẫu vote     : 6666\n",
            "  Số lớp          : 10\n",
            "  GAMMA           : 2 -> scale = 100\n",
            "  max_sum (giới hạn discrete log): 500\n",
            "  Phase 1: Khởi tạo khóa cho từng teacher & từng class\n",
            "  Ví dụ X[0], Y[0]: 9098930 4086035\n",
            "  Phase 2 - Step 1: Lượng tử hóa dự đoán\n",
            "  Phase 2 - Step 2: Tính key_factor cho từng client & lớp\n",
            "  Phase 2 - Step 3: Mã hóa & nhân các bản mã V_i^(j)\n",
            "  Phase 2 - Step 4: Giải discrete log để khôi phục S^(k,j)\n",
            "    -> Xây bảng tra discrete log một lần cho g^s (s=0..max_sum)\n",
            "    Mẫu 0 - S[0, :]: [  0   0   0   0   0   0   0 500   0   0]\n",
            "    Mẫu 1 - S[1, :]: [  0   0 500   0   0   0   0   0   0   0]\n",
            "  Phase 2 - Step 5: Chia ngược scale, lấy tổng & argmax\n",
            "  Một vài mẫu demo (sample 0-2):\n",
            "    Sample 0:\n",
            "      Dự đoán teacher 0: [2.6869555e-11 4.1804253e-13 9.2665896e-11 3.5351079e-07 1.8213380e-14\n",
            " 3.7489673e-13 4.1141590e-18 9.9999964e-01 4.6807567e-09 1.8863366e-09]\n",
            "      Tổng O_sum      : [0. 0. 0. 0. 0. 0. 0. 5. 0. 0.]\n",
            "      Trung bình O_avg: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "      Nhãn cuối cùng  : 7\n",
            "    Sample 1:\n",
            "      Dự đoán teacher 0: [5.7930383e-06 8.5001396e-08 9.9998808e-01 1.9863985e-10 4.0463962e-15\n",
            " 6.0650123e-13 2.3609742e-07 2.5892198e-11 5.7991574e-06 1.4847344e-16]\n",
            "      Tổng O_sum      : [0. 0. 5. 0. 0. 0. 0. 0. 0. 0.]\n",
            "      Trung bình O_avg: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "      Nhãn cuối cùng  : 2\n",
            "    Sample 2:\n",
            "      Dự đoán teacher 0: [1.2393976e-08 9.9999750e-01 6.3305862e-07 1.3734138e-09 9.1883925e-07\n",
            " 8.4672658e-10 5.7025236e-08 7.9698680e-07 1.0139897e-07 6.3131228e-10]\n",
            "      Tổng O_sum      : [0. 5. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "      Trung bình O_avg: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "      Nhãn cuối cùng  : 1\n",
            "\n",
            "  final_predictions shape: (6666,)\n",
            "  10 nhãn đầu: [7 2 1 0 4 1 4 9 5 9]\n",
            "  10 nhãn thực (y_test_2_3): [7 2 1 0 4 1 4 9 5 9]\n",
            "\n",
            "=== 8. HUẤN LUYỆN STUDENT MODEL TRÊN NHÃN PATE ===\n",
            "Epoch 1/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6653 - loss: 1.1380\n",
            "Epoch 2/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1420\n",
            "Epoch 3/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0822\n",
            "Epoch 4/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0485\n",
            "Epoch 5/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0342\n",
            "Epoch 6/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0261\n",
            "Epoch 7/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0219\n",
            "Epoch 8/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0154\n",
            "Epoch 9/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0096\n",
            "Epoch 10/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0072\n",
            "\n",
            "=== 9. ĐÁNH GIÁ STUDENT MODEL TRÊN 1/3 TẬP TEST CÒN LẠI ===\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0345\n",
            "\n",
            "Final test accuracy on remaining 1/3: 98.74%\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# PATE VOTE MNIST với Secure Aggregation\n",
        "# ============================================\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# =======================\n",
        "# 0. THAM SỐ PATE\n",
        "# =======================\n",
        "\n",
        "\n",
        "P = 10000019\n",
        "G = 2\n",
        "GAMMA = 2\n",
        "\n",
        "def build_dlog_table(g, p, max_log):\n",
        "    \"\"\"\n",
        "    Build bảng tra discrete log: value -> exponent\n",
        "    Tính g^s mod p cho s=0..max_log và lưu trong dict.\n",
        "    \"\"\"\n",
        "    table = {}\n",
        "    val = 1\n",
        "    for s in range(max_log + 1):\n",
        "        if val not in table:   # lưu exp nhỏ nhất\n",
        "            table[val] = s\n",
        "        val = (val * g) % p\n",
        "    return table\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 1. ĐỌC & TIỀN XỬ LÝ MNIST\n",
        "# =======================\n",
        "\n",
        "print(\"=== 1. ĐỌC DỮ LIỆU MNIST ===\")\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(\"  X_train shape:\", X_train.shape)\n",
        "print(\"  X_test  shape:\", X_test.shape)\n",
        "\n",
        "# Tiền xử lý dữ liệu\n",
        "print(\"\\n=== 2. TIỀN XỬ LÝ DỮ LIỆU ===\")\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255  # CNN input\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "print(\"  Sau reshape:\")\n",
        "print(\"  X_train shape:\", X_train.shape)\n",
        "print(\"  X_test  shape:\", X_test.shape)\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# Tách tập kiểm tra thành 2 phần: 2/3 cho PATE/Student train, 1/3 cho đánh giá\n",
        "print(\"\\n=== 3. CHIA TẬP TEST: 2/3 DÙNG PATE, 1/3 DÙNG TEST STUDENT ===\")\n",
        "split_index = len(X_test) // 3\n",
        "X_test_2_3 = X_test[:2 * split_index]\n",
        "y_test_2_3 = y_test[:2 * split_index]\n",
        "X_test_1_3 = X_test[2 * split_index:]\n",
        "y_test_1_3 = y_test[2 * split_index:]\n",
        "\n",
        "print(\"  X_test_2_3:\", X_test_2_3.shape, \"y_test_2_3:\", y_test_2_3.shape)\n",
        "print(\"  X_test_1_3:\", X_test_1_3.shape, \"y_test_1_3:\", y_test_1_3.shape)\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 2. CHIA TRAIN CHO CÁC CLIENT (TEACHER)\n",
        "# =======================\n",
        "\n",
        "print(\"\\n=== 4. CHIA DỮ LIỆU HUẤN LUYỆN CHO CÁC TEACHER ===\")\n",
        "n_clients = 5  # Số lượng client\n",
        "train_data_splits_X = np.array_split(X_train, n_clients)\n",
        "train_data_splits_y = np.array_split(y_train, n_clients)\n",
        "\n",
        "for i in range(n_clients):\n",
        "    print(f\"  Client {i+1}: X={train_data_splits_X[i].shape}, y={train_data_splits_y[i].shape}\")\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 3. ĐỊNH NGHĨA MÔ HÌNH CNN\n",
        "# =======================\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 4. TRAIN TEACHER MODELS\n",
        "# =======================\n",
        "\n",
        "print(\"\\n=== 5. HUẤN LUYỆN MỖI TEACHER (CLIENT) ===\")\n",
        "client_models = []\n",
        "for i in range(n_clients):\n",
        "    print(f\"\\n--- Training client {i+1}/{n_clients} ---\")\n",
        "    X_client = train_data_splits_X[i]\n",
        "    y_client = train_data_splits_y[i]\n",
        "\n",
        "    client_model = create_cnn_model()\n",
        "    client_model.fit(X_client, y_client, epochs=10, batch_size=64, verbose=1)\n",
        "    client_models.append(client_model)\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 5. TEACHER PREDICTIONS TRÊN 2/3 TẬP TEST\n",
        "# =======================\n",
        "\n",
        "print(\"\\n=== 6. TEACHER PREDICTIONS TRÊN 2/3 TẬP TEST ===\")\n",
        "client_predictions = []\n",
        "for i, model in enumerate(client_models):\n",
        "    print(f\"  Dự đoán từ client {i+1} ...\")\n",
        "    predictions = model.predict(X_test_2_3, verbose=0)  # (n_samples, 10)\n",
        "    client_predictions.append(predictions)\n",
        "\n",
        "print(\"  Số mảng dự đoán nhận được:\", len(client_predictions))\n",
        "print(\"  Shape dự đoán từ client 1:\", client_predictions[0].shape)\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 6. HARD VOTE VỚI SECURE AGGREGATION (PATE)\n",
        "# =======================\n",
        "\n",
        "def hard_vote_secure_agg_multiclass(predictions, num_classes, p=P, g=G, gamma=GAMMA):\n",
        "    \"\"\"\n",
        "    predictions: list length = n_clients,\n",
        "                 mỗi phần tử là mảng (n_samples, num_classes)\n",
        "                 -> xác suất softmax của từng teacher.\n",
        "\n",
        "    Trả về:\n",
        "        labels: mảng (n_samples,) chứa nhãn 0..num_classes-1.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== 7. HARD VOTE - SECURE AGGREGATION (PATE, MULTI-CLASS) ===\")\n",
        "\n",
        "    preds_list = [np.array(pr) for pr in predictions]\n",
        "    preds = np.stack(preds_list, axis=0)  # (n_clients, n_samples, num_classes)\n",
        "\n",
        "    n_clients, n_samples, num_classes2 = preds.shape\n",
        "    assert num_classes2 == num_classes, \"num_classes không khớp!\"\n",
        "\n",
        "    scale = 10 ** gamma\n",
        "    max_sum = n_clients * scale  # tối đa tổng lượng tử\n",
        "\n",
        "    print(f\"  Số client       : {n_clients}\")\n",
        "    print(f\"  Số mẫu vote     : {n_samples}\")\n",
        "    print(f\"  Số lớp          : {num_classes}\")\n",
        "    print(f\"  GAMMA           : {gamma} -> scale = {scale}\")\n",
        "    print(f\"  max_sum (giới hạn discrete log): {max_sum}\")\n",
        "\n",
        "    # -------- Phase 1: Initialization --------\n",
        "    print(\"  Phase 1: Khởi tạo khóa cho từng teacher & từng class\")\n",
        "\n",
        "    # x_i^(j), y_i^(j): shape (n_clients, num_classes)\n",
        "    x = np.random.randint(1, p - 1, size=(n_clients, num_classes), dtype=np.int64)\n",
        "    y = np.random.randint(1, p - 1, size=(n_clients, num_classes), dtype=np.int64)\n",
        "\n",
        "    # Tính X^(j), Y^(j) cho mỗi class j\n",
        "    X = np.ones(num_classes, dtype=np.int64)\n",
        "    Y = np.ones(num_classes, dtype=np.int64)\n",
        "\n",
        "    for j in range(num_classes):\n",
        "        for i in range(n_clients):\n",
        "            X[j] = (X[j] * pow(g, int(x[i, j]), p)) % p\n",
        "            Y[j] = (Y[j] * pow(g, int(y[i, j]), p)) % p\n",
        "\n",
        "    print(\"  Ví dụ X[0], Y[0]:\", X[0], Y[0])\n",
        "\n",
        "    # -------- Phase 2: Secure computation --------\n",
        "\n",
        "    # Bước 1: lượng tử hóa dự đoán\n",
        "    print(\"  Phase 2 - Step 1: Lượng tử hóa dự đoán\")\n",
        "    quantized = (preds * scale).round().astype(int)  # (n_clients, n_samples, num_classes)\n",
        "\n",
        "    # Bước 2: Tính key_factor[i, j] = X^(j)^{y_i^(j)} * (Y^(j)^{x_i^(j)})^{-1} mod p\n",
        "    print(\"  Phase 2 - Step 2: Tính key_factor cho từng client & lớp\")\n",
        "    key_factor = np.zeros((n_clients, num_classes), dtype=np.int64)\n",
        "    for i in range(n_clients):\n",
        "        for j in range(num_classes):\n",
        "            X_y = pow(int(X[j]), int(y[i, j]), p)\n",
        "            Y_x = pow(int(Y[j]), int(x[i, j]), p)\n",
        "            Y_x_inv = pow(Y_x, p - 2, p)  # nghịch đảo modulo p (Fermat)\n",
        "            key_factor[i, j] = (X_y * Y_x_inv) % p\n",
        "\n",
        "    # Bước 3: Mã hóa & aggregate\n",
        "    print(\"  Phase 2 - Step 3: Mã hóa & nhân các bản mã V_i^(j)\")\n",
        "    V_agg = np.ones((n_samples, num_classes), dtype=np.int64)\n",
        "\n",
        "    for i in range(n_clients):\n",
        "        for s in range(n_samples):\n",
        "            for j in range(num_classes):\n",
        "                g_pow = pow(g, int(quantized[i, s, j]), p)\n",
        "                V_i_s_j = (key_factor[i, j] * g_pow) % p\n",
        "                V_agg[s, j] = (V_agg[s, j] * V_i_s_j) % p\n",
        "\n",
        "    # Bước 4: Giải discrete log để khôi phục S^(k,j)\n",
        "    print(\"  Phase 2 - Step 4: Giải discrete log để khôi phục S^(k,j)\")\n",
        "    print(\"    -> Xây bảng tra discrete log một lần cho g^s (s=0..max_sum)\")\n",
        "    dlog_table = build_dlog_table(g, p, max_sum)\n",
        "\n",
        "    S = np.zeros((n_samples, num_classes), dtype=np.int64)\n",
        "    for s in range(n_samples):\n",
        "        for j in range(num_classes):\n",
        "            v_val = int(V_agg[s, j])\n",
        "            if v_val not in dlog_table:\n",
        "                raise ValueError(f\"Không tìm thấy discrete log cho V_agg[{s},{j}]={v_val}\")\n",
        "            S[s, j] = dlog_table[v_val]\n",
        "        if s < 2:  # in demo 2 mẫu đầu\n",
        "            print(f\"    Mẫu {s} - S[{s}, :]:\", S[s, :])\n",
        "\n",
        "    # Bước 5: Khôi phục tổng xác suất & hard vote\n",
        "    print(\"  Phase 2 - Step 5: Chia ngược scale, lấy tổng & argmax\")\n",
        "\n",
        "    O_sum = S.astype(float) / scale       # (n_samples, num_classes) ~ ∑ O_i^(k,j)\n",
        "    O_avg = O_sum / n_clients            # Trung bình xác suất trên các teacher\n",
        "    labels = np.argmax(O_avg, axis=1)    # Hard vote bằng argmax\n",
        "\n",
        "    print(\"  Một vài mẫu demo (sample 0-2):\")\n",
        "    for idx in range(min(3, n_samples)):\n",
        "        print(f\"    Sample {idx}:\")\n",
        "        print(f\"      Dự đoán teacher 0: {preds[0, idx]}\")\n",
        "        print(f\"      Tổng O_sum      : {O_sum[idx]}\")\n",
        "        print(f\"      Trung bình O_avg: {O_avg[idx]}\")\n",
        "        print(f\"      Nhãn cuối cùng  : {labels[idx]}\")\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "# GỌI HÀM HARD VOTE SECURE AGGREGATION\n",
        "final_predictions = hard_vote_secure_agg_multiclass(\n",
        "    client_predictions,\n",
        "    num_classes=num_classes,\n",
        "    p=P,\n",
        "    g=G,\n",
        "    gamma=GAMMA\n",
        ")\n",
        "\n",
        "print(\"\\n  final_predictions shape:\", final_predictions.shape)\n",
        "print(\"  10 nhãn đầu:\", final_predictions[:10])\n",
        "print(\"  10 nhãn thực (y_test_2_3):\", y_test_2_3[:10])\n",
        "\n",
        "\n",
        "# =======================\n",
        "# 7. HUẤN LUYỆN STUDENT MODEL\n",
        "# =======================\n",
        "\n",
        "print(\"\\n=== 8. HUẤN LUYỆN STUDENT MODEL TRÊN NHÃN PATE ===\")\n",
        "final_model = create_cnn_model()\n",
        "final_model.fit(X_test_2_3, final_predictions, epochs=10, batch_size=64, verbose=1)\n",
        "\n",
        "# =======================\n",
        "# 8. ĐÁNH GIÁ TRÊN 1/3 TẬP TEST CÒN LẠI\n",
        "# =======================\n",
        "\n",
        "print(\"\\n=== 9. ĐÁNH GIÁ STUDENT MODEL TRÊN 1/3 TẬP TEST CÒN LẠI ===\")\n",
        "loss, accuracy = final_model.evaluate(X_test_1_3, y_test_1_3, verbose=1)\n",
        "print(f\"\\nFinal test accuracy on remaining 1/3: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCuaIMiPys7P",
        "outputId": "d6c4af75-d4f2-4c78-e49b-9d108f5d096e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 'Research' folder at: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "# Đường dẫn đến thư mục Research\n",
        "path_to_research = '/content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset'\n",
        "\n",
        "# Kiểm tra xem thư mục có tồn tại không\n",
        "if os.path.exists(path_to_research):\n",
        "    print(f\"Found 'Research' folder at: {path_to_research}\")\n",
        "else:\n",
        "    print(\"The 'Research' folder does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRmoHOTOzI_G",
        "outputId": "fe29da94-df7c-4008-e928-fdfb03aeeeff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang đọc class 0 - folder: Viral Pneumonia (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/Viral Pneumonia/images)\n",
            "Đang đọc class 1 - folder: COVID (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/COVID/images)\n",
            "Đang đọc class 2 - folder: Lung_Opacity (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/Lung_Opacity/images)\n",
            "Đang đọc class 3 - folder: Normal (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/Normal/images)\n",
            "Tổng số ảnh đọc được: (21165, 224, 224)\n",
            "Tổng số nhãn        : (21165,)\n",
            "Các class tìm được  : ['Viral Pneumonia', 'COVID', 'Lung_Opacity', 'Normal']\n",
            "Shape ảnh cho CNN   : (21165, 224, 224, 1)\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset\"\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "class_names = []\n",
        "\n",
        "i = 0\n",
        "for folder_name in os.listdir(path):\n",
        "    class_folder = os.path.join(path, folder_name)\n",
        "\n",
        "    # Bỏ qua nếu không phải thư mục (phòng khi có file lẻ)\n",
        "    if not os.path.isdir(class_folder):\n",
        "        print(\"Bỏ qua (không phải thư mục class):\", class_folder)\n",
        "        continue\n",
        "\n",
        "    # Đường dẫn tới thư mục images bên trong\n",
        "    images_folder = os.path.join(class_folder, \"images\")\n",
        "    if not os.path.isdir(images_folder):\n",
        "        print(\"  Không thấy thư mục 'images' trong:\", class_folder)\n",
        "        continue\n",
        "\n",
        "    print(f\"Đang đọc class {i} - folder: {folder_name} (images_folder: {images_folder})\")\n",
        "    class_names.append(folder_name)\n",
        "\n",
        "    # Duyệt qua từng file ảnh trong /images\n",
        "    for image_name in os.listdir(images_folder):\n",
        "        image_path = os.path.join(images_folder, image_name)\n",
        "\n",
        "        # Nếu là thư mục con thì bỏ qua\n",
        "        if os.path.isdir(image_path):\n",
        "            print(\"  Bỏ qua subfolder trong images:\", image_path)\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            print(\"  Không đọc được (bỏ qua):\", image_path)\n",
        "            continue\n",
        "\n",
        "        # Chuyển grayscale\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        # Resize\n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        # Chuẩn hóa\n",
        "        img = img.astype(\"float32\") / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(i)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Tổng số ảnh đọc được:\", images.shape)\n",
        "print(\"Tổng số nhãn        :\", labels.shape)\n",
        "print(\"Các class tìm được  :\", class_names)\n",
        "\n",
        "# Nếu dùng CNN 2D: thêm dimension channels\n",
        "images_cnn = images.reshape(-1, 224, 224, 1)\n",
        "print(\"Shape ảnh cho CNN   :\", images_cnn.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "buBhNnYq8HuY",
        "outputId": "4cf12d8e-9c7f-4ddc-ebb4-017b55aec986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang đọc class 0 - folder: Viral Pneumonia (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/Viral Pneumonia/images)\n",
            "Đang đọc class 1 - folder: COVID (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/COVID/images)\n",
            "Đang đọc class 2 - folder: Lung_Opacity (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/Lung_Opacity/images)\n",
            "Đang đọc class 3 - folder: Normal (images_folder: /content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset/Normal/images)\n",
            "Tổng số ảnh đọc được: (21165, 224, 224, 3)\n",
            "Tổng số nhãn        : (21165,)\n",
            "Các class tìm được  : ['Viral Pneumonia', 'COVID', 'Lung_Opacity', 'Normal']\n",
            "Số lớp (num_classes): 4\n",
            "x_train: (14815, 224, 224, 3)\n",
            "y_train: (14815, 4)\n",
            "x_test : (6350, 224, 224, 3)\n",
            "y_test : (6350, 4)\n",
            "\n",
            "=== KIỂM TRA KIẾN TRÚC MODEL THEO BẠN ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_24 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_25 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_26 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m332928\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m21,307,456\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">332928</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,307,456</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,400,964\u001b[0m (81.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,400,964</span> (81.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,400,964\u001b[0m (81.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,400,964</span> (81.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CHIA DỮ LIỆU TRAIN CHO CÁC TEACHER ===\n",
            "  Teacher 1: x=(2963, 224, 224, 3), y=(2963, 4)\n",
            "  Teacher 2: x=(2963, 224, 224, 3), y=(2963, 4)\n",
            "  Teacher 3: x=(2963, 224, 224, 3), y=(2963, 4)\n",
            "  Teacher 4: x=(2963, 224, 224, 3), y=(2963, 4)\n",
            "  Teacher 5: x=(2963, 224, 224, 3), y=(2963, 4)\n",
            "\n",
            "=== TRAIN CÁC TEACHER MODEL ===\n",
            "\n",
            "--- Training teacher 1/5 ---\n",
            "Epoch 1/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.4098 - loss: 1.5548\n",
            "Epoch 2/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4881 - loss: 1.0919\n",
            "Epoch 3/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5464 - loss: 1.0150\n",
            "Epoch 4/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5639 - loss: 0.9781\n",
            "Epoch 5/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6178 - loss: 0.9016\n",
            "Epoch 6/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6299 - loss: 0.8805\n",
            "Epoch 7/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6479 - loss: 0.8634\n",
            "Epoch 8/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6464 - loss: 0.8299\n",
            "Epoch 9/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6453 - loss: 0.8279\n",
            "Epoch 10/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6992 - loss: 0.7643\n",
            "Epoch 11/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6998 - loss: 0.7249\n",
            "Epoch 12/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6934 - loss: 0.7251\n",
            "Epoch 13/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7255 - loss: 0.6877\n",
            "Epoch 14/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7441 - loss: 0.6481\n",
            "Epoch 15/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7389 - loss: 0.6442\n",
            "Epoch 16/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7707 - loss: 0.5815\n",
            "Epoch 17/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7758 - loss: 0.5727\n",
            "Epoch 18/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8025 - loss: 0.5375\n",
            "Epoch 19/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8023 - loss: 0.5039\n",
            "Epoch 20/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8213 - loss: 0.4711\n",
            "Epoch 21/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8026 - loss: 0.5054\n",
            "Epoch 22/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8163 - loss: 0.4533\n",
            "Epoch 23/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8433 - loss: 0.3954\n",
            "Epoch 24/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8408 - loss: 0.4098\n",
            "Epoch 25/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8601 - loss: 0.3508\n",
            "Epoch 26/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8751 - loss: 0.3251\n",
            "Epoch 27/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8825 - loss: 0.3175\n",
            "Epoch 28/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8840 - loss: 0.3001\n",
            "Epoch 29/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9000 - loss: 0.2722\n",
            "Epoch 30/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8978 - loss: 0.2575\n",
            "Epoch 31/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9171 - loss: 0.2224\n",
            "Epoch 32/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9156 - loss: 0.2195\n",
            "Epoch 33/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9103 - loss: 0.2475\n",
            "Epoch 34/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9242 - loss: 0.1951\n",
            "Epoch 35/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9166 - loss: 0.2156\n",
            "Epoch 36/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9347 - loss: 0.1750\n",
            "Epoch 37/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9305 - loss: 0.1568\n",
            "Epoch 38/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9287 - loss: 0.1813\n",
            "Epoch 39/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9350 - loss: 0.1632\n",
            "Epoch 40/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9443 - loss: 0.1446\n",
            "Epoch 41/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9433 - loss: 0.1433\n",
            "Epoch 42/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9518 - loss: 0.1335\n",
            "Epoch 43/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9492 - loss: 0.1220\n",
            "Epoch 44/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9659 - loss: 0.1013\n",
            "Epoch 45/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9726 - loss: 0.0935\n",
            "Epoch 46/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9657 - loss: 0.0839\n",
            "Epoch 47/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9720 - loss: 0.0819\n",
            "Epoch 48/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9451 - loss: 0.1600\n",
            "Epoch 49/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9645 - loss: 0.1110\n",
            "Epoch 50/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9719 - loss: 0.0753\n",
            "\n",
            "--- Training teacher 2/5 ---\n",
            "Epoch 1/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.4458 - loss: 1.3447\n",
            "Epoch 2/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5336 - loss: 1.0413\n",
            "Epoch 3/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6222 - loss: 0.9203\n",
            "Epoch 4/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6396 - loss: 0.8615\n",
            "Epoch 5/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6737 - loss: 0.7827\n",
            "Epoch 6/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7052 - loss: 0.7368\n",
            "Epoch 7/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7100 - loss: 0.7077\n",
            "Epoch 8/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7524 - loss: 0.6622\n",
            "Epoch 9/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7608 - loss: 0.6233\n",
            "Epoch 10/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7711 - loss: 0.5816\n",
            "Epoch 11/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7461 - loss: 0.6106\n",
            "Epoch 12/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7875 - loss: 0.5319\n",
            "Epoch 13/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7909 - loss: 0.5311\n",
            "Epoch 14/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8159 - loss: 0.5004\n",
            "Epoch 15/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8234 - loss: 0.4553\n",
            "Epoch 16/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8403 - loss: 0.4419\n",
            "Epoch 17/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8338 - loss: 0.4117\n",
            "Epoch 18/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8474 - loss: 0.3749\n",
            "Epoch 19/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8557 - loss: 0.3736\n",
            "Epoch 20/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8749 - loss: 0.3368\n",
            "Epoch 21/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8815 - loss: 0.3288\n",
            "Epoch 22/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8741 - loss: 0.3231\n",
            "Epoch 23/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8972 - loss: 0.2613\n",
            "Epoch 24/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9074 - loss: 0.2451\n",
            "Epoch 25/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9124 - loss: 0.2446\n",
            "Epoch 26/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9234 - loss: 0.2148\n",
            "Epoch 27/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9243 - loss: 0.2012\n",
            "Epoch 28/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9291 - loss: 0.2001\n",
            "Epoch 29/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9379 - loss: 0.1589\n",
            "Epoch 30/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9547 - loss: 0.1282\n",
            "Epoch 31/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9534 - loss: 0.1187\n",
            "Epoch 32/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9594 - loss: 0.1081\n",
            "Epoch 33/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9629 - loss: 0.1169\n",
            "Epoch 34/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.1124\n",
            "Epoch 35/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9684 - loss: 0.0946\n",
            "Epoch 36/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9752 - loss: 0.0892\n",
            "Epoch 37/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9760 - loss: 0.0720\n",
            "Epoch 38/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9711 - loss: 0.0806\n",
            "Epoch 39/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9807 - loss: 0.0651\n",
            "Epoch 40/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9796 - loss: 0.0621\n",
            "Epoch 41/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9748 - loss: 0.0801\n",
            "Epoch 42/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9844 - loss: 0.0526\n",
            "Epoch 43/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9792 - loss: 0.0715\n",
            "Epoch 44/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9806 - loss: 0.0576\n",
            "Epoch 45/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9865 - loss: 0.0478\n",
            "Epoch 46/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9868 - loss: 0.0480\n",
            "Epoch 47/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9888 - loss: 0.0344\n",
            "Epoch 48/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9797 - loss: 0.0580\n",
            "Epoch 49/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9918 - loss: 0.0378\n",
            "Epoch 50/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9857 - loss: 0.0398\n",
            "\n",
            "--- Training teacher 3/5 ---\n",
            "Epoch 1/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - accuracy: 0.4763 - loss: 1.5210\n",
            "Epoch 2/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5171 - loss: 1.0515\n",
            "Epoch 3/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5635 - loss: 0.9901\n",
            "Epoch 4/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5874 - loss: 0.9272\n",
            "Epoch 5/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6208 - loss: 0.8921\n",
            "Epoch 6/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6488 - loss: 0.8282\n",
            "Epoch 7/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6364 - loss: 0.8425\n",
            "Epoch 8/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6524 - loss: 0.8000\n",
            "Epoch 9/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6787 - loss: 0.7587\n",
            "Epoch 10/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6897 - loss: 0.7440\n",
            "Epoch 11/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6952 - loss: 0.7258\n",
            "Epoch 12/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7254 - loss: 0.6661\n",
            "Epoch 13/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7300 - loss: 0.6680\n",
            "Epoch 14/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7550 - loss: 0.6284\n",
            "Epoch 15/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7554 - loss: 0.6063\n",
            "Epoch 16/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7582 - loss: 0.5818\n",
            "Epoch 17/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8096 - loss: 0.5138\n",
            "Epoch 18/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7810 - loss: 0.5467\n",
            "Epoch 19/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7956 - loss: 0.4927\n",
            "Epoch 20/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8093 - loss: 0.4874\n",
            "Epoch 21/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.4817\n",
            "Epoch 22/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8322 - loss: 0.4272\n",
            "Epoch 23/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8526 - loss: 0.3812\n",
            "Epoch 24/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8478 - loss: 0.3971\n",
            "Epoch 25/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8720 - loss: 0.3596\n",
            "Epoch 26/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8622 - loss: 0.3829\n",
            "Epoch 27/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8726 - loss: 0.3513\n",
            "Epoch 28/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8890 - loss: 0.2906\n",
            "Epoch 29/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8873 - loss: 0.2990\n",
            "Epoch 30/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8838 - loss: 0.2908\n",
            "Epoch 31/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9121 - loss: 0.2343\n",
            "Epoch 32/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9231 - loss: 0.2174\n",
            "Epoch 33/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9216 - loss: 0.2131\n",
            "Epoch 34/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9114 - loss: 0.2195\n",
            "Epoch 35/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9279 - loss: 0.1813\n",
            "Epoch 36/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9207 - loss: 0.2013\n",
            "Epoch 37/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9380 - loss: 0.1585\n",
            "Epoch 38/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9361 - loss: 0.1714\n",
            "Epoch 39/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9221 - loss: 0.1908\n",
            "Epoch 40/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9569 - loss: 0.1205\n",
            "Epoch 41/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9583 - loss: 0.1178\n",
            "Epoch 42/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9592 - loss: 0.1171\n",
            "Epoch 43/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9552 - loss: 0.1209\n",
            "Epoch 44/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9700 - loss: 0.0957\n",
            "Epoch 45/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9734 - loss: 0.0782\n",
            "Epoch 46/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9717 - loss: 0.0858\n",
            "Epoch 47/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9671 - loss: 0.0908\n",
            "Epoch 48/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9631 - loss: 0.1053\n",
            "Epoch 49/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9549 - loss: 0.1206\n",
            "Epoch 50/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9774 - loss: 0.0700\n",
            "\n",
            "--- Training teacher 4/5 ---\n",
            "Epoch 1/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.4339 - loss: 1.3328\n",
            "Epoch 2/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5769 - loss: 0.9954\n",
            "Epoch 3/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6414 - loss: 0.8710\n",
            "Epoch 4/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6884 - loss: 0.7839\n",
            "Epoch 5/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6969 - loss: 0.7330\n",
            "Epoch 6/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7100 - loss: 0.7148\n",
            "Epoch 7/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7405 - loss: 0.6626\n",
            "Epoch 8/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7371 - loss: 0.6555\n",
            "Epoch 9/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7583 - loss: 0.6367\n",
            "Epoch 10/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7626 - loss: 0.6122\n",
            "Epoch 11/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7811 - loss: 0.5604\n",
            "Epoch 12/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8155 - loss: 0.4983\n",
            "Epoch 13/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8147 - loss: 0.4979\n",
            "Epoch 14/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8170 - loss: 0.4865\n",
            "Epoch 15/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8202 - loss: 0.4683\n",
            "Epoch 16/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8519 - loss: 0.3952\n",
            "Epoch 17/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8581 - loss: 0.3815\n",
            "Epoch 18/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8491 - loss: 0.3763\n",
            "Epoch 19/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8741 - loss: 0.3437\n",
            "Epoch 20/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8858 - loss: 0.3182\n",
            "Epoch 21/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8968 - loss: 0.2807\n",
            "Epoch 22/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8908 - loss: 0.2913\n",
            "Epoch 23/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9016 - loss: 0.2675\n",
            "Epoch 24/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9101 - loss: 0.2444\n",
            "Epoch 25/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9084 - loss: 0.2282\n",
            "Epoch 26/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9296 - loss: 0.2110\n",
            "Epoch 27/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9224 - loss: 0.2163\n",
            "Epoch 28/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9377 - loss: 0.1721\n",
            "Epoch 29/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9444 - loss: 0.1702\n",
            "Epoch 30/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9504 - loss: 0.1525\n",
            "Epoch 31/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9436 - loss: 0.1497\n",
            "Epoch 32/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9458 - loss: 0.1477\n",
            "Epoch 33/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9697 - loss: 0.0984\n",
            "Epoch 34/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9619 - loss: 0.1022\n",
            "Epoch 35/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9593 - loss: 0.1060\n",
            "Epoch 36/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9726 - loss: 0.0814\n",
            "Epoch 37/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9748 - loss: 0.0829\n",
            "Epoch 38/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9836 - loss: 0.0611\n",
            "Epoch 39/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9787 - loss: 0.0758\n",
            "Epoch 40/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9678 - loss: 0.1001\n",
            "Epoch 41/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9825 - loss: 0.0676\n",
            "Epoch 42/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9802 - loss: 0.0671\n",
            "Epoch 43/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9741 - loss: 0.0682\n",
            "Epoch 44/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9781 - loss: 0.0766\n",
            "Epoch 45/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0322\n",
            "Epoch 46/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9845 - loss: 0.0474\n",
            "Epoch 47/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9847 - loss: 0.0478\n",
            "Epoch 48/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9883 - loss: 0.0378\n",
            "Epoch 49/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9929 - loss: 0.0322\n",
            "Epoch 50/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0320\n",
            "\n",
            "--- Training teacher 5/5 ---\n",
            "Epoch 1/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.4389 - loss: 1.9470\n",
            "Epoch 2/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5220 - loss: 1.1004\n",
            "Epoch 3/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5603 - loss: 1.0495\n",
            "Epoch 4/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5885 - loss: 0.9734\n",
            "Epoch 5/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5859 - loss: 0.9793\n",
            "Epoch 6/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6088 - loss: 0.9331\n",
            "Epoch 7/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6041 - loss: 0.9526\n",
            "Epoch 8/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6096 - loss: 0.9082\n",
            "Epoch 9/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6058 - loss: 0.9207\n",
            "Epoch 10/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6043 - loss: 0.9158\n",
            "Epoch 11/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5871 - loss: 0.9161\n",
            "Epoch 12/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6073 - loss: 0.8437\n",
            "Epoch 13/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6714 - loss: 0.7528\n",
            "Epoch 14/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6783 - loss: 0.7350\n",
            "Epoch 15/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6918 - loss: 0.7158\n",
            "Epoch 16/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7319 - loss: 0.6534\n",
            "Epoch 17/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7178 - loss: 0.6679\n",
            "Epoch 18/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7623 - loss: 0.6004\n",
            "Epoch 19/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7760 - loss: 0.5753\n",
            "Epoch 20/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7833 - loss: 0.5466\n",
            "Epoch 21/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7718 - loss: 0.5378\n",
            "Epoch 22/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8067 - loss: 0.5062\n",
            "Epoch 23/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7959 - loss: 0.5371\n",
            "Epoch 24/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8174 - loss: 0.4874\n",
            "Epoch 25/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8310 - loss: 0.4390\n",
            "Epoch 26/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8306 - loss: 0.4202\n",
            "Epoch 27/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8524 - loss: 0.3975\n",
            "Epoch 28/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8565 - loss: 0.3757\n",
            "Epoch 29/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8143 - loss: 0.4932\n",
            "Epoch 30/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8659 - loss: 0.3410\n",
            "Epoch 31/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8757 - loss: 0.3290\n",
            "Epoch 32/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8847 - loss: 0.3149\n",
            "Epoch 33/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8885 - loss: 0.2817\n",
            "Epoch 34/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9092 - loss: 0.2451\n",
            "Epoch 35/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8800 - loss: 0.3123\n",
            "Epoch 36/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9159 - loss: 0.2296\n",
            "Epoch 37/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9318 - loss: 0.1885\n",
            "Epoch 38/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9316 - loss: 0.1796\n",
            "Epoch 39/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9348 - loss: 0.1835\n",
            "Epoch 40/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9370 - loss: 0.1668\n",
            "Epoch 41/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9229 - loss: 0.2119\n",
            "Epoch 42/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9527 - loss: 0.1354\n",
            "Epoch 43/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9348 - loss: 0.1746\n",
            "Epoch 44/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9606 - loss: 0.1171\n",
            "Epoch 45/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9396 - loss: 0.1586\n",
            "Epoch 46/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9472 - loss: 0.1502\n",
            "Epoch 47/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9615 - loss: 0.0951\n",
            "Epoch 48/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9738 - loss: 0.0812\n",
            "Epoch 49/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9737 - loss: 0.0848\n",
            "Epoch 50/50\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9758 - loss: 0.0671\n",
            "\n",
            "=== CHIA x_test: 2/3 PUBLIC (PATE), 1/3 PRIVATE TEST ===\n",
            "x_public      : (4232, 224, 224, 3)\n",
            "y_public_true : (4232, 4)\n",
            "x_private_test: (2118, 224, 224, 3)\n",
            "y_private_test: (2118, 4)\n",
            "\n",
            "=== TEACHER PREDICTIONS TRÊN PUBLIC DATA ===\n",
            "  Dự đoán từ teacher 1 ...\n",
            "  Dự đoán từ teacher 2 ...\n",
            "  Dự đoán từ teacher 3 ...\n",
            "  Dự đoán từ teacher 4 ...\n",
            "  Dự đoán từ teacher 5 ...\n",
            "  Số mảng dự đoán: 5\n",
            "  Shape dự đoán teacher 1: (4232, 4)\n",
            "\n",
            "=== HARD VOTE - SECURE AGGREGATION (PATE, MULTI-CLASS) ===\n",
            "  Số client       : 5\n",
            "  Số mẫu vote     : 4232\n",
            "  Số lớp (class)  : 4\n",
            "  GAMMA           : 2 -> scale = 100\n",
            "  max_sum (log max): 500\n",
            "  Phase 1: Khởi tạo khóa cho từng teacher & từng class\n",
            "  Ví dụ X[0], Y[0]: 6436392 8745690\n",
            "  Phase 2 - Step 1: Lượng tử hóa dự đoán\n",
            "  Phase 2 - Step 2: Tính key_factor cho từng client & class\n",
            "  Phase 2 - Step 3: Mã hóa & nhân các bản mã V_i^(j)\n",
            "  Phase 2 - Step 4: Giải discrete log để khôi phục S^(k,j)\n",
            "    -> Xây bảng tra discrete log cho g^s (s=0..max_sum)\n",
            "    Mẫu 0 - S[0, :]: [ 31  12   0 457]\n",
            "    Mẫu 1 - S[1, :]: [  0 450   1  49]\n",
            "  Phase 2 - Step 5: Chia ngược scale, lấy tổng & argmax\n",
            "  Một vài mẫu demo (sample 0-2):\n",
            "    Sample 0:\n",
            "      Dự đoán teacher 0: [5.5945391e-05 4.3452792e-09 3.4623093e-10 9.9994409e-01]\n",
            "      Tổng O_sum      : [0.31 0.12 0.   4.57]\n",
            "      Trung bình O_avg: [0.062 0.024 0.    0.914]\n",
            "      Nhãn cuối cùng  : 3\n",
            "    Sample 1:\n",
            "      Dự đoán teacher 0: [3.2069736e-06 9.9909234e-01 9.9089893e-06 8.9453353e-04]\n",
            "      Tổng O_sum      : [0.   4.5  0.01 0.49]\n",
            "      Trung bình O_avg: [0.    0.9   0.002 0.098]\n",
            "      Nhãn cuối cùng  : 1\n",
            "    Sample 2:\n",
            "      Dự đoán teacher 0: [1.3323422e-04 4.0274566e-01 5.7553571e-01 2.1585358e-02]\n",
            "      Tổng O_sum      : [0.   2.66 2.25 0.08]\n",
            "      Trung bình O_avg: [0.    0.532 0.45  0.016]\n",
            "      Nhãn cuối cùng  : 1\n",
            "\n",
            "Pseudo-labels (int) shape: (4232,)\n",
            "10 nhãn PATE đầu   : [3 1 1 2 2 3 2 2 3 3]\n",
            "\n",
            "=== TRAIN STUDENT MODEL TRÊN PUBLIC DATA + LABEL PATE ===\n",
            "\n",
            "=== ĐÁNH GIÁ STUDENT MODEL TRÊN 1/3 TEST CÒN LẠI ===\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9726 - loss: 0.0805\n",
            "\n",
            "Final test accuracy on remaining 1/3: 97.76%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras import layers, models, Sequential\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "# ========= 0. THAM SỐ SECURE AGGREGATION (DEMO) =========\n",
        "# Lưu ý: Đây là tham số DEMO, không dùng cho crypto thực tế\n",
        "\n",
        "P = 10000019   # p > n_clients * 10^gamma\n",
        "G = 2          # giả sử 2 là generator phù hợp\n",
        "GAMMA = 2      # giữ 2 chữ số sau dấu phẩy -> scale = 100\n",
        "\n",
        "def build_dlog_table(g, p, max_log):\n",
        "    \"\"\"\n",
        "    Xây bảng tra discrete log: value -> exponent\n",
        "    value = g^s mod p, với s = 0..max_log\n",
        "    \"\"\"\n",
        "    table = {}\n",
        "    val = 1\n",
        "    for s in range(max_log + 1):\n",
        "        if val not in table:   # lưu exp nhỏ nhất\n",
        "            table[val] = s\n",
        "        val = (val * g) % p\n",
        "    return table\n",
        "\n",
        "def hard_vote_secure_agg_multiclass(predictions, num_classes, p=P, g=G, gamma=GAMMA):\n",
        "    \"\"\"\n",
        "    predictions: list length = n_clients,\n",
        "                 mỗi phần tử là mảng (n_samples, num_classes)\n",
        "                 -> xác suất softmax của từng teacher.\n",
        "\n",
        "    Trả về:\n",
        "        labels: mảng (n_samples,) chứa nhãn 0..num_classes-1 (hard vote).\n",
        "    \"\"\"\n",
        "    print(\"\\n=== HARD VOTE - SECURE AGGREGATION (PATE, MULTI-CLASS) ===\")\n",
        "\n",
        "    preds_list = [np.array(pr) for pr in predictions]\n",
        "    preds = np.stack(preds_list, axis=0)  # (n_clients, n_samples, num_classes)\n",
        "\n",
        "    n_clients, n_samples, num_classes2 = preds.shape\n",
        "    assert num_classes2 == num_classes, \"num_classes không khớp!\"\n",
        "\n",
        "    scale = 10 ** gamma\n",
        "    max_sum = n_clients * scale  # tối đa tổng lượng tử hóa cho mỗi class\n",
        "\n",
        "    print(f\"  Số client       : {n_clients}\")\n",
        "    print(f\"  Số mẫu vote     : {n_samples}\")\n",
        "    print(f\"  Số lớp (class)  : {num_classes}\")\n",
        "    print(f\"  GAMMA           : {gamma} -> scale = {scale}\")\n",
        "    print(f\"  max_sum (log max): {max_sum}\")\n",
        "\n",
        "    # -------- Phase 1: Initialization --------\n",
        "    print(\"  Phase 1: Khởi tạo khóa cho từng teacher & từng class\")\n",
        "\n",
        "    # x_i^(j), y_i^(j): shape (n_clients, num_classes)\n",
        "    x = np.random.randint(1, p - 1, size=(n_clients, num_classes), dtype=np.int64)\n",
        "    y = np.random.randint(1, p - 1, size=(n_clients, num_classes), dtype=np.int64)\n",
        "\n",
        "    # Tính X^(j), Y^(j) cho mỗi class j\n",
        "    X = np.ones(num_classes, dtype=np.int64)\n",
        "    Y = np.ones(num_classes, dtype=np.int64)\n",
        "\n",
        "    for j in range(num_classes):\n",
        "        for i in range(n_clients):\n",
        "            X[j] = (X[j] * pow(g, int(x[i, j]), p)) % p\n",
        "            Y[j] = (Y[j] * pow(g, int(y[i, j]), p)) % p\n",
        "\n",
        "    print(\"  Ví dụ X[0], Y[0]:\", X[0], Y[0])\n",
        "\n",
        "    # -------- Phase 2: Secure computation --------\n",
        "\n",
        "    # Bước 1: lượng tử hóa dự đoán\n",
        "    print(\"  Phase 2 - Step 1: Lượng tử hóa dự đoán\")\n",
        "    quantized = (preds * scale).round().astype(int)  # (n_clients, n_samples, num_classes)\n",
        "\n",
        "    # Bước 2: Tính key_factor[i, j] = X^(j)^{y_i^(j)} * (Y^(j)^{x_i^(j)})^{-1} mod p\n",
        "    print(\"  Phase 2 - Step 2: Tính key_factor cho từng client & class\")\n",
        "    key_factor = np.zeros((n_clients, num_classes), dtype=np.int64)\n",
        "    for i in range(n_clients):\n",
        "        for j in range(num_classes):\n",
        "            X_y = pow(int(X[j]), int(y[i, j]), p)\n",
        "            Y_x = pow(int(Y[j]), int(x[i, j]), p)\n",
        "            Y_x_inv = pow(Y_x, p - 2, p)  # nghịch đảo modulo p\n",
        "            key_factor[i, j] = (X_y * Y_x_inv) % p\n",
        "\n",
        "    # Bước 3: Mã hóa & aggregate\n",
        "    print(\"  Phase 2 - Step 3: Mã hóa & nhân các bản mã V_i^(j)\")\n",
        "    V_agg = np.ones((n_samples, num_classes), dtype=np.int64)\n",
        "\n",
        "    for i in range(n_clients):\n",
        "        for s in range(n_samples):\n",
        "            for j in range(num_classes):\n",
        "                g_pow = pow(g, int(quantized[i, s, j]), p)\n",
        "                V_i_s_j = (key_factor[i, j] * g_pow) % p\n",
        "                V_agg[s, j] = (V_agg[s, j] * V_i_s_j) % p\n",
        "\n",
        "    # Bước 4: Giải discrete log để khôi phục S^(k,j)\n",
        "    print(\"  Phase 2 - Step 4: Giải discrete log để khôi phục S^(k,j)\")\n",
        "    print(\"    -> Xây bảng tra discrete log cho g^s (s=0..max_sum)\")\n",
        "    dlog_table = build_dlog_table(g, p, max_sum)\n",
        "\n",
        "    S = np.zeros((n_samples, num_classes), dtype=np.int64)\n",
        "    for s in range(n_samples):\n",
        "        for j in range(num_classes):\n",
        "            v_val = int(V_agg[s, j])\n",
        "            if v_val not in dlog_table:\n",
        "                raise ValueError(f\"Không tìm thấy discrete log cho V_agg[{s},{j}]={v_val}\")\n",
        "            S[s, j] = dlog_table[v_val]\n",
        "        if s < 2:  # in demo 2 mẫu đầu\n",
        "            print(f\"    Mẫu {s} - S[{s}, :]:\", S[s, :])\n",
        "\n",
        "    # Bước 5: Khôi phục tổng & hard vote\n",
        "    print(\"  Phase 2 - Step 5: Chia ngược scale, lấy tổng & argmax\")\n",
        "    O_sum = S.astype(float) / scale       # ∑ O_i^(k,j)\n",
        "    O_avg = O_sum / n_clients             # Trung bình xác suất\n",
        "    labels = np.argmax(O_avg, axis=1)     # Hard vote\n",
        "\n",
        "    print(\"  Một vài mẫu demo (sample 0-2):\")\n",
        "    for idx in range(min(3, n_samples)):\n",
        "        print(f\"    Sample {idx}:\")\n",
        "        print(f\"      Dự đoán teacher 0: {preds[0, idx]}\")\n",
        "        print(f\"      Tổng O_sum      : {O_sum[idx]}\")\n",
        "        print(f\"      Trung bình O_avg: {O_avg[idx]}\")\n",
        "        print(f\"      Nhãn cuối cùng  : {labels[idx]}\")\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "# ========= 1. LOAD ẢNH (RGB, s x s x 3) =========\n",
        "s = 224  # kích thước ảnh đầu vào\n",
        "\n",
        "path = \"/content/drive/MyDrive/Research/SecureAI-Lab/dataset/Covid19/COVID-19_Radiography_Dataset\"\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "class_names = []\n",
        "\n",
        "i = 0\n",
        "for folder_name in os.listdir(path):\n",
        "    class_folder = os.path.join(path, folder_name)\n",
        "\n",
        "    # Bỏ qua nếu không phải thư mục (phòng khi có file lẻ)\n",
        "    if not os.path.isdir(class_folder):\n",
        "        print(\"Bỏ qua (không phải thư mục class):\", class_folder)\n",
        "        continue\n",
        "\n",
        "    # Đường dẫn tới thư mục images bên trong mỗi class\n",
        "    images_folder = os.path.join(class_folder, \"images\")\n",
        "    if not os.path.isdir(images_folder):\n",
        "        print(\"  Không thấy thư mục 'images' trong:\", class_folder)\n",
        "        continue\n",
        "\n",
        "    print(f\"Đang đọc class {i} - folder: {folder_name} (images_folder: {images_folder})\")\n",
        "    class_names.append(folder_name)\n",
        "\n",
        "    # Duyệt qua từng file ảnh trong /images\n",
        "    for image_name in os.listdir(images_folder):\n",
        "        image_path = os.path.join(images_folder, image_name)\n",
        "\n",
        "        # Nếu là thư mục con thì bỏ qua\n",
        "        if os.path.isdir(image_path):\n",
        "            print(\"  Bỏ qua subfolder trong images:\", image_path)\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(image_path)  # BGR\n",
        "        if img is None:\n",
        "            print(\"  Không đọc được (bỏ qua):\", image_path)\n",
        "            continue\n",
        "\n",
        "        # Resize về s x s\n",
        "        img = cv2.resize(img, (s, s))\n",
        "        # Chuyển sang RGB cho \"đẹp\" (optional)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        # Chuẩn hóa\n",
        "        img = img.astype(\"float32\") / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(i)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "images = np.array(images)        # (N, s, s, 3)\n",
        "labels = np.array(labels)        # (N,)\n",
        "\n",
        "print(\"Tổng số ảnh đọc được:\", images.shape)\n",
        "print(\"Tổng số nhãn        :\", labels.shape)\n",
        "print(\"Các class tìm được  :\", class_names)\n",
        "\n",
        "num_classes = len(class_names)\n",
        "print(\"Số lớp (num_classes):\", num_classes)\n",
        "\n",
        "# ========= 2. CHUẨN BỊ LABEL & SPLIT =========\n",
        "\n",
        "label_ids = labels.copy()\n",
        "labels_cat = to_categorical(label_ids, num_classes=num_classes)   # (N, num_classes)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    images,\n",
        "    labels_cat,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=label_ids\n",
        ")\n",
        "\n",
        "print(\"x_train:\", x_train.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"x_test :\", x_test.shape)\n",
        "print(\"y_test :\", y_test.shape)\n",
        "\n",
        "# ========= 3. ĐỊNH NGHĨA MODEL CNN THEO KIẾN TRÚC BẠN ĐƯA =========\n",
        "\n",
        "def create_cnn_model(input_shape=(s, s, 3), num_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        activation=\"relu\",\n",
        "        input_shape=input_shape,\n",
        "        kernel_initializer='he_normal',\n",
        "    ))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    # fully connected\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation=\"relu\"))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    # Dòng dưới là chỗ mình generalize: dùng num_classes thay vì cố định 3\n",
        "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='SGD',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "print(\"\\n=== KIỂM TRA KIẾN TRÚC MODEL THEO BẠN ===\")\n",
        "tmp_model = create_cnn_model(input_shape=(s, s, 3), num_classes=num_classes)\n",
        "tmp_model.summary()\n",
        "del tmp_model\n",
        "\n",
        "# ========= 4. CHIA TRAIN CHO N TEACHER =========\n",
        "\n",
        "print(\"\\n=== CHIA DỮ LIỆU TRAIN CHO CÁC TEACHER ===\")\n",
        "n_clients = 5\n",
        "train_splits_x = np.array_split(x_train, n_clients)\n",
        "train_splits_y = np.array_split(y_train, n_clients)\n",
        "\n",
        "for idx in range(n_clients):\n",
        "    print(f\"  Teacher {idx+1}: x={train_splits_x[idx].shape}, y={train_splits_y[idx].shape}\")\n",
        "\n",
        "# ========= 5. TRAIN TEACHER MODELS =========\n",
        "\n",
        "print(\"\\n=== TRAIN CÁC TEACHER MODEL ===\")\n",
        "teacher_models = []\n",
        "for i in range(n_clients):\n",
        "    print(f\"\\n--- Training teacher {i+1}/{n_clients} ---\")\n",
        "    model_teacher = create_cnn_model(input_shape=(s, s, 3), num_classes=num_classes)\n",
        "    model_teacher.fit(\n",
        "        train_splits_x[i],\n",
        "        train_splits_y[i],\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "    teacher_models.append(model_teacher)\n",
        "\n",
        "# ========= 6. CHIA x_test LÀM PUBLIC (2/3) & PRIVATE TEST (1/3) =========\n",
        "\n",
        "print(\"\\n=== CHIA x_test: 2/3 PUBLIC (PATE), 1/3 PRIVATE TEST ===\")\n",
        "split_idx = len(x_test) // 3\n",
        "x_public = x_test[:2 * split_idx]\n",
        "y_public_true = y_test[:2 * split_idx]        # chỉ để tham khảo\n",
        "x_private_test = x_test[2 * split_idx:]\n",
        "y_private_test = y_test[2 * split_idx:]\n",
        "\n",
        "print(\"x_public      :\", x_public.shape)\n",
        "print(\"y_public_true :\", y_public_true.shape)\n",
        "print(\"x_private_test:\", x_private_test.shape)\n",
        "print(\"y_private_test:\", y_private_test.shape)\n",
        "\n",
        "# ========= 7. TEACHERS DỰ ĐOÁN TRÊN PUBLIC DATA =========\n",
        "\n",
        "print(\"\\n=== TEACHER PREDICTIONS TRÊN PUBLIC DATA ===\")\n",
        "teacher_predictions = []\n",
        "for i, m in enumerate(teacher_models):\n",
        "    print(f\"  Dự đoán từ teacher {i+1} ...\")\n",
        "    preds = m.predict(x_public, verbose=0)   # (n_public, num_classes)\n",
        "    teacher_predictions.append(preds)\n",
        "\n",
        "print(\"  Số mảng dự đoán:\", len(teacher_predictions))\n",
        "print(\"  Shape dự đoán teacher 1:\", teacher_predictions[0].shape)\n",
        "\n",
        "# ========= 8. SECURE AGGREGATION HARD VOTE (PATE) =========\n",
        "\n",
        "pseudo_labels_int = hard_vote_secure_agg_multiclass(\n",
        "    teacher_predictions,\n",
        "    num_classes=num_classes,\n",
        "    p=P,\n",
        "    g=G,\n",
        "    gamma=GAMMA\n",
        ")  # shape: (n_public,)\n",
        "\n",
        "print(\"\\nPseudo-labels (int) shape:\", pseudo_labels_int.shape)\n",
        "print(\"10 nhãn PATE đầu   :\", pseudo_labels_int[:10])\n",
        "\n",
        "# Chuyển sang one-hot để train student với categorical_crossentropy\n",
        "pseudo_labels_cat = to_categorical(pseudo_labels_int, num_classes=num_classes)\n",
        "x_private_test=x_public\n",
        "y_private_test=pseudo_labels_cat\n",
        "\n",
        "# ========= 9. TRAIN STUDENT MODEL TRÊN NHÃN PATE =========\n",
        "\n",
        "print(\"\\n=== TRAIN STUDENT MODEL TRÊN PUBLIC DATA + LABEL PATE ===\")\n",
        "student_model = create_cnn_model(input_shape=(s, s, 3), num_classes=num_classes)\n",
        "student_model.fit(\n",
        "    x_public,\n",
        "    pseudo_labels_cat,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# ========= 10. EVALUATE STUDENT TRÊN PRIVATE TEST =========\n",
        "\n",
        "print(\"\\n=== ĐÁNH GIÁ STUDENT MODEL TRÊN 1/3 TEST CÒN LẠI ===\")\n",
        "loss, acc = student_model.evaluate(x_private_test, y_private_test, verbose=1)\n",
        "print(f\"\\nFinal test accuracy on remaining 1/3: {acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 9. TRAIN STUDENT MODEL TRÊN NHÃN PATE =========\n",
        "\n",
        "print(\"\\n=== TRAIN STUDENT MODEL TRÊN PUBLIC DATA + LABEL PATE ===\")\n",
        "student_model = create_cnn_model(input_shape=(s, s, 3), num_classes=num_classes)\n",
        "student_model.fit(\n",
        "    x_public,\n",
        "    pseudo_labels_cat,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# ========= 10. EVALUATE STUDENT TRÊN PRIVATE TEST =========\n",
        "\n",
        "print(\"\\n=== ĐÁNH GIÁ STUDENT MODEL TRÊN 1/3 TEST CÒN LẠI ===\")\n",
        "loss, acc = student_model.evaluate(x_private_test, y_private_test, verbose=1)\n",
        "print(f\"\\nFinal test accuracy on remaining 1/3: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0gnPVMthvTA",
        "outputId": "09b3885c-17d9-4a90-a0c0-aa3421480789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAIN STUDENT MODEL TRÊN PUBLIC DATA + LABEL PATE ===\n",
            "\n",
            "=== ĐÁNH GIÁ STUDENT MODEL TRÊN 1/3 TEST CÒN LẠI ===\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9618 - loss: 0.1144\n",
            "\n",
            "Final test accuracy on remaining 1/3: 96.34%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}